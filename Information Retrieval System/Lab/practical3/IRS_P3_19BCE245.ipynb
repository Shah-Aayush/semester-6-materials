{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "IRS_P3_19BCE245.ipynb",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IRS Practical 3\n",
        "> 19BCE245 - Aayush Shah\n",
        "- Vector Space model (TFIDF) \n",
        "  - Countvectorizer"
      ],
      "metadata": {
        "id": "4mOYQQikJfTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Explore `CountVectorizer` and `TfidfVectorizer`"
      ],
      "metadata": {
        "id": "kWK4ctDkJg98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - ### with `CountVectorizer` : "
      ],
      "metadata": {
        "id": "bVPQUI07WHTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
      ],
      "metadata": {
        "id": "bx86JA5cJRRK",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "  'This is the first document.',\n",
        "  'This document is the second document.',\n",
        "  'And this is the third one.',\n",
        "  'Is this the first document?',\n",
        "]"
      ],
      "metadata": {
        "id": "_WpoN3i8JVwP",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "QXX04vHZK5WX",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.toarray())"
      ],
      "metadata": {
        "id": "adOKx2FMLHGj",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2,2))\n",
        "X2 = vectorizer2.fit_transform(corpus)\n",
        "vectorizer2.get_feature_names_out()"
      ],
      "metadata": {
        "id": "cK7c3nGWLJm4",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X2.toarray())"
      ],
      "metadata": {
        "id": "yO2GO1DlLeJz",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer3 = CountVectorizer(decode_error='ignore', stop_words='english', ngram_range=(1,3))\n",
        "X3 = vectorizer3.fit_transform(corpus)\n",
        "vectorizer3.get_feature_names_out()"
      ],
      "metadata": {
        "id": "WcPOL8V9LqcP",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X3.toarray())"
      ],
      "metadata": {
        "id": "nuQGooaTMMij",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - ### with `TfidfVectorizer` : "
      ],
      "metadata": {
        "id": "5EddNOZtWPLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "xZRJuM2VWOwt",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X.toarray())"
      ],
      "metadata": {
        "id": "nG8pTByXWuGf",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Do 1st part with file handling."
      ],
      "metadata": {
        "id": "0BTcdr2pMrw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making files\n",
        "for i in range(len(corpus)):\n",
        "  f = open(\"data\"+str(i+1)+\".txt\", \"w\")\n",
        "  f.write(corpus[i])\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "Hi1nndOvMwFw",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading files\n",
        "extracted_corpus = []\n",
        "for i in range(len(corpus)):\n",
        "  f = open(\"data\"+str(i+1)+\".txt\",'r')\n",
        "  extracted_corpus.append(f.read())\n",
        "\n",
        "print(extracted_corpus)"
      ],
      "metadata": {
        "id": "PjwIF_43NHrC",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting document names from current directory\n",
        "doc_names = os.listdir('.')\n",
        "print(doc_names)\n",
        "doc_names = [i for i in doc_names if ('.txt' in i)]\n",
        "print(doc_names)"
      ],
      "metadata": {
        "id": "Kx1F8fNbTNee",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ### with `CountVectorizer` : "
      ],
      "metadata": {
        "id": "A-pDhVz7Xh14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer4 = CountVectorizer(input=doc_names)\n",
        "X4 = vectorizer4.fit_transform(corpus)\n",
        "vectorizer4.get_feature_names_out()"
      ],
      "metadata": {
        "id": "FF_RqiYPS27Z",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# files = ['data1.txt','data2.txt','data3.txt','data4.txt']"
      ],
      "metadata": {
        "id": "m_KHDAoxSLLl",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer4 = CountVectorizer(input=doc_names)\n",
        "X4 = vectorizer4.fit_transform(extracted_corpus)\n",
        "vectorizer4.get_feature_names_out()"
      ],
      "metadata": {
        "id": "e3a_Pb2GNy7l",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X4.toarray())"
      ],
      "metadata": {
        "id": "PVWN_-PMSWFC",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X4.toarray())"
      ],
      "metadata": {
        "id": "L_TW4t30N54K",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ### with `TfidfVectorizer` : "
      ],
      "metadata": {
        "id": "pc2iqJVuXjJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(input=doc_names)\n",
        "X5 = vectorizer.fit_transform(extracted_corpus)\n",
        "vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "Md4C26LPXkqX",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X5.shape)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X5.toarray())"
      ],
      "metadata": {
        "id": "0dDwU6lnX9Qr",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Take part in competition \n",
        "> [Refer this notebook](https://www.kaggle.com/adamschroeder/countvectorizer-tfidfvectorizer-predict-comments/notebook)"
      ],
      "metadata": {
        "id": "GhJxxlYNOOso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
      ],
      "metadata": {
        "trusted": true,
        "id": "lBlJEN8ISl41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import  matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score , accuracy_score , confusion_matrix , f1_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "trusted": true,
        "id": "NL5sc3jwSl41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df  =  pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\n",
        "train_df"
      ],
      "metadata": {
        "trusted": true,
        "id": "84pL6NXASl41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df=pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip')\n",
        "test_df"
      ],
      "metadata": {
        "trusted": true,
        "id": "SniI3s1uSl42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_review_text(text):\n",
        "    text = text.lower()  # covert the text to lowercase\n",
        "    text = re.sub('<.*?>','',text).strip() # remove html chars\n",
        "    text = re.sub('\\[|\\(.*\\]|\\)','', text).strip() # remove text in square brackets and parenthesis\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation)) # remove punctuation marks\n",
        "    text = re.sub(\"(\\\\W)\",\" \",text).strip() # remove non-ascii chars\n",
        "    text = re.sub('\\S*\\d\\S*\\s*','', text).strip()  # remove words containing numbers\n",
        "    return text.strip()"
      ],
      "metadata": {
        "trusted": true,
        "id": "LUy3DtPFSl42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.comment_text = train_df.comment_text.astype(str)\n",
        "train_df.comment_text = train_df.comment_text.apply(clean_review_text)\n",
        "train_df.comment_text.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "l6W7k2IHSl42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "snow_stemmer = SnowballStemmer(language='english')\n",
        "\n",
        "stopwords = nlp.Defaults.stop_words\n",
        "def apply_stemmer(text):\n",
        "    words = text.split()\n",
        "    sent = [snow_stemmer.stem(word) for word in words if not word in set(stopwords)]\n",
        "    return ' '.join(sent)"
      ],
      "metadata": {
        "trusted": true,
        "id": "fypS67URSl42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.comment_text = train_df.comment_text.apply(apply_stemmer)\n",
        "train_df.comment_text.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "tXgjoTl-Sl43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_df.comment_text\n",
        "y = train_df.drop(['id','comment_text'],axis = 1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "FLXmmzbBSl43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test =  train_test_split(X,y,test_size = 0.2,random_state = 45)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Sh_HDXlKSl44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectorizer = TfidfVectorizer(\n",
        "    strip_accents='unicode',     \n",
        "    analyzer='word',            \n",
        "    token_pattern=r'\\w{1,}',    \n",
        "    ngram_range=(1, 3),         \n",
        "    stop_words='english',\n",
        "    sublinear_tf=True)\n",
        "\n",
        "word_vectorizer.fit(x_train)    \n",
        "train_word_features = word_vectorizer.transform(x_train)"
      ],
      "metadata": {
        "trusted": true,
        "id": "IcgSfVQWSl44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_transformed = word_vectorizer.transform(x_train)\n",
        "X_test_transformed = word_vectorizer.transform(x_test)"
      ],
      "metadata": {
        "trusted": true,
        "id": "YwBVjFmJSl44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "seed=100\n",
        "\n",
        "log_reg = LogisticRegression(C = 10, penalty='l2', solver = 'liblinear', random_state=seed)\n",
        "\n",
        "# fit model\n",
        "classifier_ovr_log = OneVsRestClassifier(log_reg)\n",
        "classifier_ovr_log.fit(X_train_transformed, y_train)"
      ],
      "metadata": {
        "trusted": true,
        "id": "JwoNSXsUSl44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred_proba = classifier_ovr_log.predict_proba(X_train_transformed)\n",
        "y_test_pred_proba = classifier_ovr_log.predict_proba(X_test_transformed)"
      ],
      "metadata": {
        "trusted": true,
        "id": "29emzOOWSl44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_test_predictions(df,classifier):\n",
        "    df.comment_text = df.comment_text.apply(clean_review_text)\n",
        "    df.comment_text = df.comment_text.apply(apply_stemmer)\n",
        "    X_test = df.comment_text\n",
        "    X_test_transformed = word_vectorizer.transform(X_test)\n",
        "    y_test_pred = classifier.predict_proba(X_test_transformed)\n",
        "    return y_test_pred"
      ],
      "metadata": {
        "trusted": true,
        "id": "wQFMVNUASl45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=make_test_predictions(test_df,classifier_ovr_log)\n",
        "y_pred"
      ],
      "metadata": {
        "trusted": true,
        "id": "nx0az8kQSl45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_df = pd.DataFrame(y_pred,columns=y.columns)\n",
        "y_pred_df"
      ],
      "metadata": {
        "trusted": true,
        "id": "YgdHh1zxSl45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.concat([test_df.id, y_pred_df], axis=1)\n",
        "submission_df.to_csv('submission.csv', index = False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "8MdNY_OLSl46"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}